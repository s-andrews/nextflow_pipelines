#!/usr/bin/env nextflow
nextflow.enable.dsl=2

// last modified 20 Jan 2025

params.outdir = "."
params.verbose = false
params.single_end = true

params.umibam2_args = ''
params.dual = false // params are handed over automatically

params.samtools_sort_args = ''
params.samtools_index_args = ''
params.no_output = false

params.help = false
// Show help message and exit
if (params.help){
    helpMessage()
    exit 0
}

if (params.verbose){
    println ("[WORKFLOW] UMIBAM2 ARGS ARE: "       + params.umibam2_args)
}

//include { makeFilesChannel; getFileBaseNames }  from './nf_modules/files_bam.mod.nf'
include { UMIBAM2 }                             from './nf_modules/umibam2.mod.nf'
include { SAMTOOLS_SORT }                       from './nf_modules/samtools.mod.nf'  params(no_output: params.no_output)
include { SAMTOOLS_INDEX2 }                     from './nf_modules/samtools.mod.nf'  params(no_output: params.no_output)

// file_ch = makeFilesChannel(args)
file_ch = Channel .fromPath(args)    // UmiBam expects just the path to be passed in
    
workflow {

    main:

        SAMTOOLS_SORT  (file_ch, params.outdir, params.samtools_sort_args, params.verbose)
        SAMTOOLS_INDEX2 (SAMTOOLS_SORT.out.bam, params.outdir, params.samtools_index_args, params.verbose)
      				        
        // Deduplication
        UMIBAM2 (SAMTOOLS_INDEX2.out.bam, SAMTOOLS_INDEX2.out.bai, params.outdir, params.umibam2_args, params.verbose)

}

// Since workflows with very long command lines tend to fail to get rendered at all, I was experimenting with a
// minimal execution summary report so we at least know what the working directory was...
workflow.onComplete {

    def msg = """\
        Pipeline execution summary
        ---------------------------
        Jobname     : ${workflow.runName}
        Completed at: ${workflow.complete}
        Duration    : ${workflow.duration}
        Success     : ${workflow.success}
        workDir     : ${workflow.workDir}
        exit status : ${workflow.exitStatus}
        """
    .stripIndent()

    sendMail(to: "${workflow.userName}@babraham.ac.uk", subject: 'Minimal pipeline execution report', body: msg)
}

def helpMessage() {
 
    log.info"""
    >>

    
    SYNOPSIS:

    This single-tool workflow takes in a list of filenames in BAM format, and de-duplicates these files based on mapping position
    as well as the UMI sequence (on the stone compute cluster at Babraham).

    This only works for single-end data.

    If you run UmiBam in this stand-alone workflow it is assumed that you know what you are doing, i.e. BAM files need to contain
    a UMI sequence as the last entry of each read ID, separated by a colon, e.g. @HWUSI:...:CAGTTAGC. If called as is, UmiBam
    is run in default mode (we are adding the option '--umi' unless the file is specified to contain dual UMIs (see option '--dual').
    To add additional parameters, please consider tool-specific arguments that are compatible with UmiBam (see '--umibam_args' below).


              ==============================================================================================================


    USAGE:

    nf_umibam2 [options] <input BAM files>
    
    Mandatory arguments:
    ====================

      <input BAM files>               List of input files in BAM format, e.g. '*bam'. The files are automatically processed as
                                      single-end or paired end files (determined via the @PG line).


    Other options:
    ==============
     
      --outdir [str]                  Path to the output directory. [Default: current working directory]
    
      --verbose                       More verbose status messages. [Default: OFF]
      --help                          Displays this help message and exits.

    Workflow options:
    =================

    Please note the single '-' hyphen for the following options!

      -resume                         If a pipeline workflow has been interrupted or stopped (e.g. by accidentally closing a laptop),
                                      this option will attempt to resume the workflow at the point it got interrupted by using
                                      Nextflow's caching mechanism. This may save a lot of time.

      -bg                             Sends the entire workflow into the background, thus disconnecting it from the terminal session.
                                      This option launches a daemon process (which will keep running on the headnode) that watches over
                                      your workflow, and submits new jobs to the SLURM queue as required. Use this option for big pipeline
                                      jobs, or whenever you do not want to watch the status progress yourself. Upon completion, the
                                      pipeline will send you an email with the job details. This option is HIGHLY RECOMMENDED!

      -process.executor=local         Temporarily changes where the workflow is executed to the 'local' machine. See also the nextflow.config
                                      file for more details. [Default: slurm] 
    

    <<
    """.stripIndent()

}

